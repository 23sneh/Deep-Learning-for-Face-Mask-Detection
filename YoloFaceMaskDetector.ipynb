{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "gCHDAerPu9Yq",
    "outputId": "32dd50f2-8a42-4fdc-f1b9-b1ba09edff35"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "upjtZ9uD4NHU"
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import lxml.etree\n",
    "import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Add,\n",
    "    Concatenate,\n",
    "    Conv2D,\n",
    "    Input,\n",
    "    Lambda,\n",
    "    LeakyReLU,\n",
    "    MaxPool2D,\n",
    "    UpSampling2D,\n",
    "    ZeroPadding2D,\n",
    "    BatchNormalization,\n",
    ")\n",
    "from tensorflow.keras.losses import (\n",
    "    binary_crossentropy,\n",
    "    sparse_categorical_crossentropy\n",
    ")\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import (\n",
    "    ReduceLROnPlateau,\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    TensorBoard\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dX4JxWHm4NHe"
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for physical_device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8wheYRzNwAut",
    "outputId": "d4dcb716-598c-42ad-b6bf-31bbdd9f4fe9"
   },
   "outputs": [],
   "source": [
    "!unzip /content/drive/My\\ Drive/ML/faceMaskDataset/dataset.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JPcuym5eww4j"
   },
   "outputs": [],
   "source": [
    "!cp /content/drive/My\\ Drive/ML/Weights/arch.weights ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1z8pIaxT4NHo",
    "outputId": "2058ec0f-7649-494c-bcdf-74e41c055783"
   },
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JqKmzBNk4NHw",
    "outputId": "98bd26d6-c694-4513-ced5-8d023f73344f"
   },
   "outputs": [],
   "source": [
    "!wget https://pjreddie.com/media/files/arch.weights -O ./arch.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s_BQ0YXf4NH1"
   },
   "outputs": [],
   "source": [
    "YOLOV3_LAYER_LIST = [\n",
    "    'yolo_darknet',\n",
    "    'yolo_conv_0',\n",
    "    'yolo_output_0',\n",
    "    'yolo_conv_1',\n",
    "    'yolo_output_1',\n",
    "    'yolo_conv_2',\n",
    "    'yolo_output_2',\n",
    "]\n",
    "\n",
    "\n",
    "def load_darknet_weights(model, weights_file, tiny=False):\n",
    "    wf = open(weights_file, 'rb')\n",
    "    major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)\n",
    "\n",
    "    layers = YOLOV3_LAYER_LIST\n",
    "\n",
    "    for layer_name in layers:\n",
    "        sub_model = model.get_layer(layer_name)\n",
    "        for i, layer in enumerate(sub_model.layers):\n",
    "            if not layer.name.startswith('conv2d'):\n",
    "                continue\n",
    "            batch_norm = None\n",
    "            if i + 1 < len(sub_model.layers) and \\\n",
    "                    sub_model.layers[i + 1].name.startswith('batch_norm'):\n",
    "                batch_norm = sub_model.layers[i + 1]\n",
    "\n",
    "            print(\"{}/{} {}\".format(\n",
    "                sub_model.name, layer.name, 'bn' if batch_norm else 'bias'))\n",
    "\n",
    "            filters = layer.filters\n",
    "            size = layer.kernel_size[0]\n",
    "            in_dim = layer.input_shape[-1]\n",
    "\n",
    "            if batch_norm is None:\n",
    "                conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n",
    "            else:\n",
    "                # darknet [beta, gamma, mean, variance]\n",
    "                bn_weights = np.fromfile(\n",
    "                    wf, dtype=np.float32, count=4 * filters)\n",
    "                # tf [gamma, beta, mean, variance]\n",
    "                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n",
    "\n",
    "            # darknet shape (out_dim, in_dim, height, width)\n",
    "            conv_shape = (filters, in_dim, size, size)\n",
    "            conv_weights = np.fromfile(\n",
    "                wf, dtype=np.float32, count=np.product(conv_shape))\n",
    "            # tf shape (height, width, in_dim, out_dim)\n",
    "            conv_weights = conv_weights.reshape(\n",
    "                conv_shape).transpose([2, 3, 1, 0])\n",
    "\n",
    "            if batch_norm is None:\n",
    "                layer.set_weights([conv_weights, conv_bias])\n",
    "            else:\n",
    "                layer.set_weights([conv_weights])\n",
    "                batch_norm.set_weights(bn_weights)\n",
    "\n",
    "    assert len(wf.read()) == 0, 'failed to read all data'\n",
    "    wf.close()\n",
    "\n",
    "\n",
    "def broadcast_iou(box_1, box_2):\n",
    "    # box_1: (..., (x1, y1, x2, y2))\n",
    "    # box_2: (N, (x1, y1, x2, y2))\n",
    "\n",
    "    # broadcast boxes\n",
    "    box_1 = tf.expand_dims(box_1, -2)\n",
    "    box_2 = tf.expand_dims(box_2, 0)\n",
    "    # new_shape: (..., N, (x1, y1, x2, y2))\n",
    "    new_shape = tf.broadcast_dynamic_shape(tf.shape(box_1), tf.shape(box_2))\n",
    "    box_1 = tf.broadcast_to(box_1, new_shape)\n",
    "    box_2 = tf.broadcast_to(box_2, new_shape)\n",
    "\n",
    "    int_w = tf.maximum(tf.minimum(box_1[..., 2], box_2[..., 2]) -\n",
    "                       tf.maximum(box_1[..., 0], box_2[..., 0]), 0)\n",
    "    int_h = tf.maximum(tf.minimum(box_1[..., 3], box_2[..., 3]) -\n",
    "                       tf.maximum(box_1[..., 1], box_2[..., 1]), 0)\n",
    "    int_area = int_w * int_h\n",
    "    box_1_area = (box_1[..., 2] - box_1[..., 0]) * \\\n",
    "                 (box_1[..., 3] - box_1[..., 1])\n",
    "    box_2_area = (box_2[..., 2] - box_2[..., 0]) * \\\n",
    "                 (box_2[..., 3] - box_2[..., 1])\n",
    "    return int_area / (box_1_area + box_2_area - int_area)\n",
    "\n",
    "\n",
    "def draw_outputs(img, outputs, class_names):\n",
    "    boxes, objectness, classes, nums = outputs\n",
    "    boxes, objectness, classes, nums = boxes[0], objectness[0], classes[0], nums[0]\n",
    "    wh = np.flip(img.shape[0:2])\n",
    "    for i in range(nums):\n",
    "        x1y1 = tuple((np.array(boxes[i][0:2]) * wh).astype(np.int32))\n",
    "        x2y2 = tuple((np.array(boxes[i][2:4]) * wh).astype(np.int32))\n",
    "        img = cv2.rectangle(img, x1y1, x2y2, (255, 0, 0), 2)\n",
    "        img = cv2.putText(img, '{} {:.4f}'.format(\n",
    "            class_names[int(classes[i])], objectness[i]),\n",
    "                          x1y1, cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)\n",
    "    return img\n",
    "\n",
    "\n",
    "def draw_labels(x, y, class_names):\n",
    "    img = x.numpy()\n",
    "    boxes, classes = tf.split(y, (4, 1), axis=-1)\n",
    "    classes = classes[..., 0]\n",
    "    wh = np.flip(img.shape[0:2])\n",
    "    for i in range(len(boxes)):\n",
    "        x1y1 = tuple((np.array(boxes[i][0:2]) * wh).astype(np.int32))\n",
    "        x2y2 = tuple((np.array(boxes[i][2:4]) * wh).astype(np.int32))\n",
    "        img = cv2.rectangle(img, x1y1, x2y2, (255, 0, 0), 2)\n",
    "        img = cv2.putText(img, class_names[classes[i]],\n",
    "                          x1y1, cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "                          1, (0, 0, 255), 2)\n",
    "    return img\n",
    "\n",
    "\n",
    "def freeze_all(model, frozen=True):\n",
    "    \n",
    "    model.trainable = not frozen\n",
    "    if isinstance(model, tf.keras.Model):\n",
    "        for l in model.layers:\n",
    "            \n",
    "            freeze_all(l, frozen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UjDoblHs4NH5"
   },
   "outputs": [],
   "source": [
    "\n",
    "yolo_max_boxes = 150\n",
    "yolo_iou_threshold = 0.5\n",
    "yolo_score_threshold = 0.5\n",
    "\n",
    "yolo_anchors = np.array([(10, 13), (16, 30), (33, 23), (30, 61), (62, 45),\n",
    "                         (59, 119), (116, 90), (156, 198), (373, 326)],\n",
    "                        np.float32) / 416\n",
    "yolo_anchor_masks = np.array([[6, 7, 8], [3, 4, 5], [0, 1, 2]])\n",
    "\n",
    "\n",
    "def DarknetConv(x, filters, size, strides=1, batch_norm=True):\n",
    "    if strides == 1:\n",
    "        padding = 'same'\n",
    "    else:\n",
    "        x = ZeroPadding2D(((1, 0), (1, 0)))(x)  # top left half-padding\n",
    "        padding = 'valid'\n",
    "    x = Conv2D(filters=filters, kernel_size=size,\n",
    "               strides=strides, padding=padding,\n",
    "               use_bias=not batch_norm, kernel_regularizer=l2(0.0005))(x)\n",
    "    if batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def DarknetResidual(x, filters):\n",
    "    prev = x\n",
    "    x = DarknetConv(x, filters // 2, 1)\n",
    "    x = DarknetConv(x, filters, 3)\n",
    "    x = Add()([prev, x])\n",
    "    return x\n",
    "\n",
    "\n",
    "def DarknetBlock(x, filters, blocks):\n",
    "    x = DarknetConv(x, filters, 3, strides=2)\n",
    "    for _ in range(blocks):\n",
    "        x = DarknetResidual(x, filters)\n",
    "    return x\n",
    "\n",
    "\n",
    "def Darknet(name=None):\n",
    "    x = inputs = Input([None, None, 3])\n",
    "    x = DarknetConv(x, 32, 3)\n",
    "    x = DarknetBlock(x, 64, 1)\n",
    "    x = DarknetBlock(x, 128, 2)  # skip connection\n",
    "    x = x_36 = DarknetBlock(x, 256, 8)  # skip connection\n",
    "    x = x_61 = DarknetBlock(x, 512, 8)\n",
    "    x = DarknetBlock(x, 1024, 4)\n",
    "    return tf.keras.Model(inputs, (x_36, x_61, x), name=name)\n",
    "\n",
    "\n",
    "def DarknetTiny(name=None):\n",
    "    x = inputs = Input([None, None, 3])\n",
    "    x = DarknetConv(x, 16, 3)\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = DarknetConv(x, 32, 3)\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = DarknetConv(x, 64, 3)\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = DarknetConv(x, 128, 3)\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = x_8 = DarknetConv(x, 256, 3)  # skip connection\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = DarknetConv(x, 512, 3)\n",
    "    x = MaxPool2D(2, 1, 'same')(x)\n",
    "    x = DarknetConv(x, 1024, 3)\n",
    "    return tf.keras.Model(inputs, (x_8, x), name=name)\n",
    "\n",
    "\n",
    "def YoloConv(filters, name=None):\n",
    "    def yolo_conv(x_in):\n",
    "        if isinstance(x_in, tuple):\n",
    "            inputs = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])\n",
    "            x, x_skip = inputs\n",
    "\n",
    "            # concat with skip connection\n",
    "            x = DarknetConv(x, filters, 1)\n",
    "            x = UpSampling2D(2)(x)\n",
    "            x = Concatenate()([x, x_skip])\n",
    "        else:\n",
    "            x = inputs = Input(x_in.shape[1:])\n",
    "\n",
    "        x = DarknetConv(x, filters, 1)\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        x = DarknetConv(x, filters, 1)\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        x = DarknetConv(x, filters, 1)\n",
    "        return Model(inputs, x, name=name)(x_in)\n",
    "\n",
    "    return yolo_conv\n",
    "\n",
    "\n",
    "# def YoloConvTiny(filters, name=None):\n",
    "#     def yolo_conv(x_in):\n",
    "#         if isinstance(x_in, tuple):\n",
    "#             inputs = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])\n",
    "#             x, x_skip = inputs\n",
    "#\n",
    "#             # concat with skip connection\n",
    "#             x = DarknetConv(x, filters, 1)\n",
    "#             x = UpSampling2D(2)(x)\n",
    "#             x = Concatenate()([x, x_skip])\n",
    "#         else:\n",
    "#             x = inputs = Input(x_in.shape[1:])\n",
    "#             x = DarknetConv(x, filters, 1)\n",
    "#         return Model(inputs, x, name=name)(x_in)\n",
    "#\n",
    "#     return yolo_conv\n",
    "\n",
    "\n",
    "def YoloOutput(filters, anchors, classes, name=None):\n",
    "    def yolo_output(x_in):\n",
    "        x = inputs = Input(x_in.shape[1:])\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        x = DarknetConv(x, anchors * (classes + 5), 1, batch_norm=False)\n",
    "        x = Lambda(lambda x: tf.reshape(x, (-1, tf.shape(x)[1], tf.shape(x)[2],\n",
    "                                            anchors, classes + 5)))(x)\n",
    "        return tf.keras.Model(inputs, x, name=name)(x_in)\n",
    "\n",
    "    return yolo_output\n",
    "\n",
    "\n",
    "def yolo_boxes(pred, anchors, classes):\n",
    "    # pred: (batch_size, grid, grid, anchors, (x, y, w, h, obj, ...classes))\n",
    "    grid_size = tf.shape(pred)[1]\n",
    "    box_xy, box_wh, objectness, class_probs = tf.split(\n",
    "        pred, (2, 2, 1, classes), axis=-1)\n",
    "\n",
    "    box_xy = tf.sigmoid(box_xy)\n",
    "    objectness = tf.sigmoid(objectness)\n",
    "    class_probs = tf.sigmoid(class_probs)\n",
    "    pred_box = tf.concat((box_xy, box_wh), axis=-1)  # original xywh for loss\n",
    "\n",
    "    # !!! grid[x][y] == (y, x)\n",
    "    grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "    grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)  # [gx, gy, 1, 2]\n",
    "\n",
    "    box_xy = (box_xy + tf.cast(grid, tf.float32)) / tf.cast(grid_size, tf.float32)\n",
    "    box_wh = tf.exp(box_wh) * anchors\n",
    "\n",
    "    box_x1y1 = box_xy - box_wh / 2\n",
    "    box_x2y2 = box_xy + box_wh / 2\n",
    "    bbox = tf.concat([box_x1y1, box_x2y2], axis=-1)\n",
    "\n",
    "    return bbox, objectness, class_probs, pred_box\n",
    "\n",
    "\n",
    "def yolo_nms(outputs, anchors, masks, classes):\n",
    "    # boxes, conf, type\n",
    "    b, c, t = [], [], []\n",
    "\n",
    "    for o in outputs:\n",
    "        b.append(tf.reshape(o[0], (tf.shape(o[0])[0], -1, tf.shape(o[0])[-1])))\n",
    "        c.append(tf.reshape(o[1], (tf.shape(o[1])[0], -1, tf.shape(o[1])[-1])))\n",
    "        t.append(tf.reshape(o[2], (tf.shape(o[2])[0], -1, tf.shape(o[2])[-1])))\n",
    "\n",
    "    bbox = tf.concat(b, axis=1)\n",
    "    confidence = tf.concat(c, axis=1)\n",
    "    class_probs = tf.concat(t, axis=1)\n",
    "\n",
    "    scores = confidence * class_probs\n",
    "    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "        boxes=tf.reshape(bbox, (tf.shape(bbox)[0], -1, 1, 4)),\n",
    "        scores=tf.reshape(\n",
    "            scores, (tf.shape(scores)[0], -1, tf.shape(scores)[-1])),\n",
    "        max_output_size_per_class=100,\n",
    "        max_total_size=100,\n",
    "        iou_threshold=0.5,\n",
    "        score_threshold=0.5\n",
    "    )\n",
    "    return boxes, scores, classes, valid_detections\n",
    "\n",
    "\n",
    "def YoloV3(size=None, channels=3, anchors=yolo_anchors, masks=yolo_anchor_masks, classes=80, training=False):\n",
    "    x = inputs = Input([size, size, channels], name='input')\n",
    "\n",
    "    x_36, x_61, x = Darknet(name='yolo_darknet')(x)\n",
    "\n",
    "    x = YoloConv(512, name='yolo_conv_0')(x)\n",
    "    output_0 = YoloOutput(512, len(masks[0]), classes, name='yolo_output_0')(x)\n",
    "\n",
    "    x = YoloConv(256, name='yolo_conv_1')((x, x_61))\n",
    "    output_1 = YoloOutput(256, len(masks[1]), classes, name='yolo_output_1')(x)\n",
    "\n",
    "    x = YoloConv(128, name='yolo_conv_2')((x, x_36))\n",
    "    output_2 = YoloOutput(128, len(masks[2]), classes, name='yolo_output_2')(x)\n",
    "\n",
    "    if training:\n",
    "        return Model(inputs, (output_0, output_1, output_2), name='yolov3')\n",
    "\n",
    "    boxes_0 = Lambda(lambda x: yolo_boxes(x, anchors[masks[0]], classes),\n",
    "                     name='yolo_boxes_0')(output_0)\n",
    "    boxes_1 = Lambda(lambda x: yolo_boxes(x, anchors[masks[1]], classes),\n",
    "                     name='yolo_boxes_1')(output_1)\n",
    "    boxes_2 = Lambda(lambda x: yolo_boxes(x, anchors[masks[2]], classes),\n",
    "                     name='yolo_boxes_2')(output_2)\n",
    "\n",
    "    outputs = Lambda(lambda x: yolo_nms(x, anchors, masks, classes),\n",
    "                     name='yolo_nms')((boxes_0[:3], boxes_1[:3], boxes_2[:3]))\n",
    "    return Model(inputs, outputs, name='yolov3')\n",
    "\n",
    "\n",
    "def YoloLoss(anchors, classes=80, ignore_thresh=0.5):\n",
    "    def yolo_loss(y_true, y_pred):\n",
    "        # 1. transform all pred outputs\n",
    "        # y_pred: (batch_size, grid, grid, anchors, (x, y, w, h, obj, ...cls))\n",
    "        pred_box, pred_obj, pred_class, pred_xywh = yolo_boxes(y_pred, anchors, classes)\n",
    "        pred_xy = pred_xywh[..., 0:2]\n",
    "        pred_wh = pred_xywh[..., 2:4]\n",
    "\n",
    "        # 2. transform all true outputs\n",
    "        # y_true: (batch_size, grid, grid, anchors, (x1, y1, x2, y2, obj, cls))\n",
    "        true_box, true_obj, true_class_idx = tf.split(y_true, (4, 1, 1), axis=-1)\n",
    "        true_xy = (true_box[..., 0:2] + true_box[..., 2:4]) / 2\n",
    "        true_wh = true_box[..., 2:4] - true_box[..., 0:2]\n",
    "\n",
    "        # give higher weights to small boxes\n",
    "        box_loss_scale = 2 - true_wh[..., 0] * true_wh[..., 1]\n",
    "\n",
    "        # 3. inverting the pred box equations\n",
    "        grid_size = tf.shape(y_true)[1]\n",
    "        grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "        grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
    "        true_xy = true_xy * tf.cast(grid_size, tf.float32) - tf.cast(grid, tf.float32)\n",
    "        true_wh = tf.math.log(true_wh / anchors)\n",
    "        true_wh = tf.where(tf.math.is_inf(true_wh), tf.zeros_like(true_wh), true_wh)\n",
    "\n",
    "        # 4. calculate all masks\n",
    "        obj_mask = tf.squeeze(true_obj, -1)\n",
    "        # ignore false positive when iou is over threshold\n",
    "        best_iou = tf.map_fn(\n",
    "            lambda x: tf.reduce_max(broadcast_iou(x[0], tf.boolean_mask(x[1], tf.cast(x[2], tf.bool))), axis=-1),\n",
    "            (pred_box, true_box, obj_mask),\n",
    "            tf.float32)\n",
    "        ignore_mask = tf.cast(best_iou < ignore_thresh, tf.float32)\n",
    "\n",
    "        # 5. calculate all losses\n",
    "        xy_loss = obj_mask * box_loss_scale * tf.reduce_sum(tf.square(true_xy - pred_xy), axis=-1)\n",
    "        wh_loss = obj_mask * box_loss_scale * tf.reduce_sum(tf.square(true_wh - pred_wh), axis=-1)\n",
    "        obj_loss = binary_crossentropy(true_obj, pred_obj)\n",
    "        obj_loss = obj_mask * obj_loss + (1 - obj_mask) * ignore_mask * obj_loss\n",
    "        # TODO: use binary_crossentropy instead\n",
    "        class_loss = obj_mask * sparse_categorical_crossentropy(true_class_idx, pred_class)\n",
    "\n",
    "        # 6. sum over (batch, gridx, gridy, anchors) => (batch, 1)\n",
    "        xy_loss = tf.reduce_sum(xy_loss, axis=(1, 2, 3))\n",
    "        wh_loss = tf.reduce_sum(wh_loss, axis=(1, 2, 3))\n",
    "        obj_loss = tf.reduce_sum(obj_loss, axis=(1, 2, 3))\n",
    "        class_loss = tf.reduce_sum(class_loss, axis=(1, 2, 3))\n",
    "\n",
    "        return xy_loss + wh_loss + obj_loss + class_loss\n",
    "\n",
    "    return yolo_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Q6B3IRLQ4NH9",
    "outputId": "53617893-b1c9-4920-b249-ecc111cd3d81"
   },
   "outputs": [],
   "source": [
    "\n",
    "def load():\n",
    "    yolo = YoloV3(classes=80)\n",
    "    yolo.summary()\n",
    "    print('model created')\n",
    "    load_darknet_weights(yolo, './yolov3.weights')\n",
    "    print('weights loaded')\n",
    "    img = np.random.random((1, 320, 320, 3)).astype(np.float32)\n",
    "    output = yolo(img)\n",
    "    print('sanity check passed')\n",
    "    yolo.save_weights('./checkpoints/yolov3.tf')\n",
    "    print('weights saved')\n",
    "\n",
    "\n",
    "load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2d1a27f2-726b-40cd-ad15-ee6ca3249084",
    "_uuid": "ec12b90b-23fa-4f55-b332-8cc53423f548",
    "colab": {},
    "colab_type": "code",
    "id": "OaN2UmVv4NID"
   },
   "outputs": [],
   "source": [
    "data_dir = './'\n",
    "train_output_file = './maskdetection.tfrecord'\n",
    "valid_output_file = './maskdetection_val.tfrecord'\n",
    "classes = './faceMask.names'\n",
    "\n",
    "\n",
    "def build_example(annotation, class_map):\n",
    "    img_path = os.path.join(data_dir,'images', annotation['filename'])\n",
    "    img_raw = open(img_path, 'rb').read()\n",
    "    key = hashlib.sha256(img_raw).hexdigest()\n",
    "\n",
    "    width = int(annotation['size']['width'])\n",
    "    height = int(annotation['size']['height'])\n",
    "\n",
    "    xmin = []\n",
    "    ymin = []\n",
    "    xmax = []\n",
    "    ymax = []\n",
    "    classes = []\n",
    "    classes_text = []\n",
    "    truncated = []\n",
    "    views = []\n",
    "    difficult_obj = []\n",
    "    if 'object' in annotation:\n",
    "        for obj in annotation['object']:\n",
    "            difficult = bool(int(obj['difficult']))\n",
    "            difficult_obj.append(int(difficult))\n",
    "\n",
    "            xmin.append(float(obj['bndbox']['xmin']) / width)\n",
    "            ymin.append(float(obj['bndbox']['ymin']) / height)\n",
    "            xmax.append(float(obj['bndbox']['xmax']) / width)\n",
    "            ymax.append(float(obj['bndbox']['ymax']) / height)\n",
    "            classes_text.append(obj['name'].encode('utf8'))\n",
    "            classes.append(class_map[obj['name']])\n",
    "            truncated.append(int(obj['truncated']))\n",
    "            views.append(obj['pose'].encode('utf8'))\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
    "        'image/width': tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
    "        'image/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[\n",
    "            annotation['filename'].encode('utf8')])),\n",
    "        'image/source_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[\n",
    "            annotation['filename'].encode('utf8')])),\n",
    "        'image/key/sha256': tf.train.Feature(bytes_list=tf.train.BytesList(value=[key.encode('utf8')])),\n",
    "        'image/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])),\n",
    "        'image/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=['jpeg'.encode('utf8')])),\n",
    "        'image/object/bbox/xmin': tf.train.Feature(float_list=tf.train.FloatList(value=xmin)),\n",
    "        'image/object/bbox/xmax': tf.train.Feature(float_list=tf.train.FloatList(value=xmax)),\n",
    "        'image/object/bbox/ymin': tf.train.Feature(float_list=tf.train.FloatList(value=ymin)),\n",
    "        'image/object/bbox/ymax': tf.train.Feature(float_list=tf.train.FloatList(value=ymax)),\n",
    "        'image/object/class/text': tf.train.Feature(bytes_list=tf.train.BytesList(value=classes_text)),\n",
    "        'image/object/class/label': tf.train.Feature(int64_list=tf.train.Int64List(value=classes)),\n",
    "        'image/object/difficult': tf.train.Feature(int64_list=tf.train.Int64List(value=difficult_obj)),\n",
    "        'image/object/truncated': tf.train.Feature(int64_list=tf.train.Int64List(value=truncated)),\n",
    "        'image/object/view': tf.train.Feature(bytes_list=tf.train.BytesList(value=views)),\n",
    "    }))\n",
    "    return example\n",
    "\n",
    "\n",
    "def parse_xml(xml):\n",
    "    if not len(xml):\n",
    "        return {xml.tag: xml.text}\n",
    "    result = {}\n",
    "    for child in xml:\n",
    "        child_result = parse_xml(child)\n",
    "        if child.tag != 'object':\n",
    "            result[child.tag] = child_result[child.tag]\n",
    "        else:\n",
    "            if child.tag not in result:\n",
    "                result[child.tag] = []\n",
    "            result[child.tag].append(child_result[child.tag])\n",
    "    return {xml.tag: result}\n",
    "\n",
    "\n",
    "def create_train():\n",
    "    class_map = {name: idx for idx, name in enumerate(open(classes).read().splitlines())}\n",
    "    print(\"Class mapping loaded: \", class_map)\n",
    "\n",
    "    writer = tf.io.TFRecordWriter(train_output_file)\n",
    "    image_list = os.listdir(os.path.join(data_dir, 'images'))\n",
    "    print(f\"Image list loaded: {len(image_list)}\")\n",
    "    for image in tqdm.tqdm(image_list[0: 700]):\n",
    "        name, _ = image.split('.')\n",
    "        annotation_xml = os.path.join(data_dir, 'annotations', name + '.xml')\n",
    "        annotation_xml = lxml.etree.fromstring(open(annotation_xml).read())\n",
    "        annotation = parse_xml(annotation_xml)['annotation']\n",
    "        tf_example = build_example(annotation, class_map)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    writer.close()\n",
    "    print(\"Done\")\n",
    "    \n",
    "    \n",
    "def create_valid():\n",
    "    class_map = {name: idx for idx, name in enumerate(open(classes).read().splitlines())}\n",
    "    print(\"Class mapping loaded: \", class_map)\n",
    "\n",
    "    writer = tf.io.TFRecordWriter(valid_output_file)\n",
    "    image_list = os.listdir(os.path.join(data_dir, 'images'))\n",
    "    print(f\"Image list loaded: {len(image_list)}\")\n",
    "    for image in tqdm.tqdm(image_list[701: ]):\n",
    "        name, _ = image.split('.')\n",
    "        annotation_xml = os.path.join(data_dir, 'annotations', name + '.xml')\n",
    "        annotation_xml = lxml.etree.fromstring(open(annotation_xml).read())\n",
    "        annotation = parse_xml(annotation_xml)['annotation']\n",
    "        tf_example = build_example(annotation, class_map)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    writer.close()\n",
    "    print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "8zZcx0ki4NIG",
    "outputId": "34c44e29-e543-4c07-ec28-dd6be9d1f932"
   },
   "outputs": [],
   "source": [
    "create_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "ko4yPURh4NIJ",
    "outputId": "b29bca10-6e2d-4fe3-fd45-1dbbfe485f68"
   },
   "outputs": [],
   "source": [
    "create_valid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j_3a5Zkq4NIL"
   },
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SdB0f88X4NIM"
   },
   "outputs": [],
   "source": [
    "\n",
    "@tf.function\n",
    "def transform_targets_for_output(y_true, grid_size, anchor_idxs):\n",
    "    # y_true: (N, boxes, (x1, y1, x2, y2, class, best_anchor))\n",
    "    N = tf.shape(y_true)[0]\n",
    "\n",
    "    # y_true_out: (N, grid, grid, anchors, [x, y, w, h, obj, class])\n",
    "    y_true_out = tf.zeros(\n",
    "        (N, grid_size, grid_size, tf.shape(anchor_idxs)[0], 6))\n",
    "\n",
    "    anchor_idxs = tf.cast(anchor_idxs, tf.int32)\n",
    "\n",
    "    indexes = tf.TensorArray(tf.int32, 1, dynamic_size=True)\n",
    "    updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\n",
    "    idx = 0\n",
    "    for i in tf.range(N):\n",
    "        for j in tf.range(tf.shape(y_true)[1]):\n",
    "            if tf.equal(y_true[i][j][2], 0):\n",
    "                continue\n",
    "            anchor_eq = tf.equal(\n",
    "                anchor_idxs, tf.cast(y_true[i][j][5], tf.int32))\n",
    "\n",
    "            if tf.reduce_any(anchor_eq):\n",
    "                box = y_true[i][j][0:4]\n",
    "                box_xy = (y_true[i][j][0:2] + y_true[i][j][2:4]) / 2\n",
    "\n",
    "                anchor_idx = tf.cast(tf.where(anchor_eq), tf.int32)\n",
    "                grid_xy = tf.cast(box_xy // (1 / grid_size), tf.int32)\n",
    "\n",
    "                # grid[y][x][anchor] = (tx, ty, bw, bh, obj, class)\n",
    "                indexes = indexes.write(\n",
    "                    idx, [i, grid_xy[1], grid_xy[0], anchor_idx[0][0]])\n",
    "                updates = updates.write(\n",
    "                    idx, [box[0], box[1], box[2], box[3], 1, y_true[i][j][4]])\n",
    "                idx += 1\n",
    "\n",
    "    # tf.print(indexes.stack())\n",
    "    # tf.print(updates.stack())\n",
    "\n",
    "    return tf.tensor_scatter_nd_update(\n",
    "        y_true_out, indexes.stack(), updates.stack())\n",
    "\n",
    "\n",
    "def transform_targets(y_train, anchors, anchor_masks, size):\n",
    "    y_outs = []\n",
    "    grid_size = size // 32\n",
    "\n",
    "    # calculate anchor index for true boxes\n",
    "    anchors = tf.cast(anchors, tf.float32)\n",
    "    anchor_area = anchors[..., 0] * anchors[..., 1]\n",
    "    box_wh = y_train[..., 2:4] - y_train[..., 0:2]\n",
    "    box_wh = tf.tile(tf.expand_dims(box_wh, -2),\n",
    "                     (1, 1, tf.shape(anchors)[0], 1))\n",
    "    box_area = box_wh[..., 0] * box_wh[..., 1]\n",
    "    intersection = tf.minimum(box_wh[..., 0], anchors[..., 0]) * \\\n",
    "                   tf.minimum(box_wh[..., 1], anchors[..., 1])\n",
    "    iou = intersection / (box_area + anchor_area - intersection)\n",
    "    anchor_idx = tf.cast(tf.argmax(iou, axis=-1), tf.float32)\n",
    "    anchor_idx = tf.expand_dims(anchor_idx, axis=-1)\n",
    "\n",
    "    y_train = tf.concat([y_train, anchor_idx], axis=-1)\n",
    "\n",
    "    for anchor_idxs in anchor_masks:\n",
    "        y_outs.append(transform_targets_for_output(\n",
    "            y_train, grid_size, anchor_idxs))\n",
    "        grid_size *= 2\n",
    "\n",
    "    return tuple(y_outs)\n",
    "\n",
    "\n",
    "def transform_images(x_train, size):\n",
    "    x_train = tf.image.resize(x_train, (size, size))\n",
    "    x_train = x_train / 255\n",
    "    return x_train\n",
    "\n",
    "\n",
    "IMAGE_FEATURE_MAP = {\n",
    "    # 'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "    # 'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "    # 'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "    # 'image/source_id': tf.io.FixedLenFeature([], tf.string),\n",
    "    # 'image/key/sha256': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "    # 'image/format': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/class/text': tf.io.VarLenFeature(tf.string),\n",
    "    # 'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
    "    # 'image/object/difficult': tf.io.VarLenFeature(tf.int64),\n",
    "    # 'image/object/truncated': tf.io.VarLenFeature(tf.int64),\n",
    "    # 'image/object/view': tf.io.VarLenFeature(tf.string),\n",
    "}\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def parse_tfrecord(tfrecord, class_table, size):\n",
    "    x = tf.io.parse_single_example(tfrecord, IMAGE_FEATURE_MAP)\n",
    "    x_train = tf.image.decode_png(x['image/encoded'], channels=3)\n",
    "    x_train = tf.image.resize(x_train, (size, size))\n",
    "    \n",
    "    class_text = tf.sparse.to_dense(\n",
    "        x['image/object/class/text'], default_value='')\n",
    "    \n",
    "    labels = tf.cast(class_table.lookup(class_text), tf.float32)\n",
    "    y_train = tf.stack([tf.sparse.to_dense(x['image/object/bbox/xmin']),\n",
    "                        tf.sparse.to_dense(x['image/object/bbox/ymin']),\n",
    "                        tf.sparse.to_dense(x['image/object/bbox/xmax']),\n",
    "                        tf.sparse.to_dense(x['image/object/bbox/ymax']),\n",
    "                        labels], axis=1)\n",
    "    \n",
    "    \n",
    "\n",
    "    paddings = [[0, yolo_max_boxes - tf.shape(y_train)[0]], [0, 0]]\n",
    "    y_train = tf.pad(y_train, paddings)\n",
    "\n",
    "    return x_train, y_train\n",
    "\n",
    "\n",
    "def load_tfrecord_dataset(file_pattern, class_file, size=416):\n",
    "    LINE_NUMBER = -1 #tf.lookup.TextFileIndex.LINE_NUMBER\n",
    "    class_table = tf.lookup.StaticHashTable(tf.lookup.TextFileInitializer(\n",
    "        class_file, tf.string, 0, tf.int64, LINE_NUMBER, delimiter=\"\\n\"), -1)\n",
    "\n",
    "    files = tf.data.Dataset.list_files(file_pattern)\n",
    "    dataset = files.flat_map(tf.data.TFRecordDataset)\n",
    "    return dataset.map(lambda x: parse_tfrecord(x, class_table, size))\n",
    "\n",
    "\n",
    "def load_fake_dataset():\n",
    "    x_train = tf.image.decode_jpeg(\n",
    "        open('./data/girl.png', 'rb').read(), channels=3)\n",
    "    x_train = tf.expand_dims(x_train, axis=0)\n",
    "\n",
    "    labels = [\n",
    "                 [0.18494931, 0.03049111, 0.9435849, 0.96302897, 0],\n",
    "                 [0.01586703, 0.35938117, 0.17582396, 0.6069674, 56],\n",
    "                 [0.09158827, 0.48252046, 0.26967454, 0.6403017, 67]\n",
    "             ] + [[0, 0, 0, 0, 0]] * 5\n",
    "    y_train = tf.convert_to_tensor(labels, tf.float32)\n",
    "    y_train = tf.expand_dims(y_train, axis=0)\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices((x_train, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "vk0V0USJ4NIO",
    "outputId": "aabdbd37-4b40-407e-c087-568f5d232e32"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3PXcoh-X4NIZ"
   },
   "outputs": [],
   "source": [
    "dataset = './maskdetection.tfrecord'\n",
    "valid_dataset = './maskdetection_val.tfrecord'\n",
    "weights = './checkpoints/yolov3.tf'\n",
    "size = 416\n",
    "epochs = 100\n",
    "batch_size = 8\n",
    "learning_rate = 1e-3\n",
    "num_classes = 80\n",
    "weights_num_classes = 3\n",
    "classes = './data/faceMask.names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qy1resxx4NIb"
   },
   "outputs": [],
   "source": [
    "train_dataset = load_tfrecord_dataset(dataset, classes, size)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=512)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.map(lambda x, y: (transform_images(x, size),transform_targets(y, yolo_anchors, yolo_anchor_masks, size)))\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "val_dataset = load_tfrecord_dataset(valid_dataset, classes, size)\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "val_dataset = val_dataset.map(lambda x, y: (transform_images(x, size),transform_targets(y, yolo_anchors, yolo_anchor_masks, size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nh6bxUxI4NIh",
    "outputId": "564424f1-b853-4e5a-9a36-50a4bc571ee9"
   },
   "outputs": [],
   "source": [
    "\n",
    "model = YoloV3(size, training=True, classes=weights_num_classes)\n",
    "anchors = yolo_anchors\n",
    "anchor_masks = yolo_anchor_masks\n",
    "\n",
    "\n",
    "model_pretrained = YoloV3(size, training=True, classes=num_classes)\n",
    "model_pretrained.load_weights(weights)\n",
    "\n",
    "model.get_layer('yolo_darknet').set_weights(model_pretrained.get_layer('yolo_darknet').get_weights())\n",
    "freeze_all(model.get_layer('yolo_darknet'))\n",
    "# for l in model.layers:\n",
    "#   if not l.name.startswith('yolo_output'):\n",
    "#     l.set_weights(model_pretrained.get_layer(l.name).get_weights())\n",
    "#     freeze_all(l)\n",
    "# model.get_layer('yolo_darknet').trainable = False\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "loss = [YoloLoss(anchors[mask], classes=weights_num_classes) for mask in anchor_masks]\n",
    "\n",
    "avg_loss = tf.keras.metrics.Mean('loss', dtype=tf.float32)\n",
    "avg_val_loss = tf.keras.metrics.Mean('val_loss', dtype=tf.float32)\n",
    "\n",
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, model=model)\n",
    "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)\n",
    "ckpt.restore(manager.latest_checkpoint)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for batch, (images, labels) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = model(images, training=True)\n",
    "            regularization_loss = tf.reduce_sum(model.losses)\n",
    "            pred_loss = []\n",
    "            for output, label, loss_fn in zip(outputs, labels, loss):\n",
    "                pred_loss.append(loss_fn(label, output))\n",
    "            total_loss = tf.reduce_sum(pred_loss) + regularization_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(\n",
    "            zip(grads, model.trainable_variables))\n",
    "\n",
    "        print(\"epoch={}_train_batch={}, total_loss={}, pred_loss={}\".format(\n",
    "            epoch, batch, total_loss.numpy(),\n",
    "            list(map(lambda x: np.sum(x.numpy()), pred_loss))))\n",
    "        avg_loss.update_state(total_loss)\n",
    "\n",
    "    for batch, (images, labels) in enumerate(val_dataset):\n",
    "        outputs = model(images)\n",
    "        regularization_loss = tf.reduce_sum(model.losses)\n",
    "        pred_loss = []\n",
    "        for output, label, loss_fn in zip(outputs, labels, loss):\n",
    "            pred_loss.append(loss_fn(label, output))\n",
    "        total_loss = tf.reduce_sum(pred_loss) + regularization_loss\n",
    "\n",
    "        print(\"epoch={}_val_batch={}, total_val_loss={}, pred_val_loss{}\".format(\n",
    "            epoch, batch, total_loss.numpy(),\n",
    "            list(map(lambda x: np.sum(x.numpy()), pred_loss))))\n",
    "        avg_val_loss.update_state(total_loss)\n",
    "\n",
    "    print(\"epoch={}, train: avg_loss={}, val: avg_val_loss={}\".format(\n",
    "        epoch,\n",
    "        avg_loss.result().numpy(),\n",
    "        avg_val_loss.result().numpy()))\n",
    "\n",
    "    avg_loss.reset_states()\n",
    "    avg_val_loss.reset_states()\n",
    "    ckpt.step.assign_add(1)\n",
    "    save_path = manager.save()\n",
    "    print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))\n",
    "    # model.save_weights('./new_checkpoints/yolov3_train_{}.tf'.format(epoch))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "4HCKWLcB4NIj",
    "outputId": "67ef3397-0d81-4b26-ae51-9cda2aabee7e"
   },
   "outputs": [],
   "source": [
    "!wget https://static01.nyt.com/images/2020/02/17/opinion/input/input-jumbo.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r-93wk974NIm"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread('./input-jumbo.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z5WVK82Sgw2_"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yyhNLd5VMq8L",
    "outputId": "97272294-0e3c-42b7-dffa-1845d10cdcd3"
   },
   "outputs": [],
   "source": [
    "yolo = YoloV3(classes=weights_num_classes)\n",
    "# yolo.load_weights('./tf_ckpts/ckpt-8').expect_partial()\n",
    "optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, model=yolo)\n",
    "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)\n",
    "latest = tf.train.latest_checkpoint('./tf_ckpts/')\n",
    "ckpt.restore(latest)\n",
    "model = ckpt.model\n",
    "for l in model.layers:\n",
    "  yolo.get_layer(l.name).set_weights(model.get_layer(l.name).get_weights())\n",
    "class_names = [c.strip() for c in open('./data/faceMask.names').readlines()]\n",
    "\n",
    "img_in = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_in = tf.expand_dims(img_in, 0)\n",
    "img_in = transform_images(img_in, 416)\n",
    "\n",
    "t1 = time.time()\n",
    "boxes, scores, classes, nums = yolo(img_in)\n",
    "t2 = time.time()\n",
    "\n",
    "img = draw_outputs(img, (boxes, scores, classes, nums), class_names)\n",
    "print(t2 - t1)\n",
    "# img = cv2.putText(img, \"Time: {:.2f}ms\".format(sum(times) / len(times) * 1000), (0, 30),cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "colab_type": "code",
    "id": "hRr2tV_3TIzF",
    "outputId": "5632456a-608f-439d-a59f-ec1acba782bf"
   },
   "outputs": [],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "cv2.imshow(\"test\", img)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "YoloFaceMaskDetector.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
